<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="managedCuda : ManagedCuda aims an easy integration of NVidia&#39;s CUDA in .net applications written in C#, Visual Basic or any other .net language.">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>managedCuda</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/kunzmi/managedCuda">View on GitHub</a>

          <h1 id="project_title">managedCuda</h1>
          <h2 id="project_tagline">ManagedCuda aims an easy integration of NVidia&#39;s CUDA in .net applications written in C#, Visual Basic or any other .net language.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/kunzmi/managedCuda/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/kunzmi/managedCuda/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="welcome-to-managedcuda" class="anchor" href="#welcome-to-managedcuda" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome to managedCuda</h3>

<p>managedCuda combines Cuda's GPU computing power with the comfort of managed .net code. While offering access to the entire feature set of Cuda's driver API, managedCuda has type safe wrapper classes for every handle defined by the API. ManagedCuda also includes wrappers for all Cuda based libraries, as there were CUFFT, CURAND, CUSPARSE, CUBLAS, CUSOLVE, NPP and NVRTC. </p>

<h3>
<a id="what-managedcuda-is-not" class="anchor" href="#what-managedcuda-is-not" aria-hidden="true"><span class="octicon octicon-link"></span></a>What managedCuda is not</h3>

<p>managedCuda is not a code converter. Which means that no C# code will be translated to Cuda. Every cuda kernel that you want to use has to be written in CUDA-C and must be compiled to PTX or CUBIN format using the NVCC toolchain.</p>

<h3>
<a id="what-managedcuda-is" class="anchor" href="#what-managedcuda-is" aria-hidden="true"><span class="octicon octicon-link"></span></a>What managedCuda is</h3>

<p>managedCuda is the right library if you want to accelerate your .net application with Cuda, and this without any restrictions. As every kernel is written in plain CUDA-C, all Cuda specific features are maintained. Even future improvements to Cuda by NVIDIA can be integrated without any changes in your application host code.</p>

<h3>
<a id="side-note" class="anchor" href="#side-note" aria-hidden="true"><span class="octicon octicon-link"></span></a>Side note</h3>

<p>Currently managedCuda is still hosted on <a href="managedcuda.codeplex.com">codeplex</a>. Latest with the upcoming 7.5 release, managedCuda will move to github.</p>

<h3>
<a id="sample-code" class="anchor" href="#sample-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sample code</h3>

<p>VectorAdd.cu as given by the Cuda SDK samples:</p>

<pre><code>//Kernel code:
extern "C"  {   
    // Device code
    __global__ void VecAdd(const float* A, const float* B, float* C, int N)
    {
        int i = blockDim.x * blockIdx.x + threadIdx.x;
        if (i &lt; N)
            C[i] = A[i] + B[i];
    }
}
</code></pre>

<p>Corresponding C# code to call the kernel:</p>

<pre><code>int N = 50000;
int deviceID = 0;
CudaContext ctx = new CudaContext(deviceID);
CudaKernel kernel = ctx.LoadKernel("vectorAdd.ptx", "VecAdd");
kernel.GridDimensions = (N + 255) / 256;
kernel.BlockDimensions = 256;

// Allocate input vectors h_A and h_B in host memory
float[] h_A = new float[N];
float[] h_B = new float[N];

// TODO: Initialize input vectors h_A, h_B

// Allocate vectors in device memory and copy vectors from host memory to device memory 
CudaDeviceVariable&lt;float&gt; d_A = h_A;
CudaDeviceVariable&lt;float&gt; d_B = h_B;
CudaDeviceVariable&lt;float&gt; d_C = new CudaDeviceVariable&lt;float&gt;(N);

// Invoke kernel
kernel.Run(d_A.DevicePointer, d_B.DevicePointer, d_C.DevicePointer, N);

// Copy result from device memory to host memory
// h_C contains the result in host memory
float[] h_C = d_C;
</code></pre>

<p>Sample showing the simple and elegant integration of NPP</p>

<pre><code>//Load an image
Bitmap bmp = new Bitmap("niceImage.png");

//Alloc device memory using NPP images
NPPImage_8uC3 bmp_d = new NPPImage_8uC3(bmp.Width, bmp.Height);
NPPImage_8uC3 bmpDest_d = new NPPImage_8uC3(bmp.Width, bmp.Height);

//Copy image to GPU
bmp_d.CopyToDevice(bmp);
//Run a NPP function
bmp_d.FilterGaussBorder(bmpDest_d, MaskSize.Size_5_X_5, NppiBorderType.Replicate);
//Copy result back to host
bmpDest_d.CopyToHost(bmp);
//Use the result
bmp.Save("niceImageFiltered.png");
</code></pre>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">managedCuda maintained by <a href="https://github.com/kunzmi">kunzmi</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
