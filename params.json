{"name":"managedCuda","tagline":"ManagedCuda aims an easy integration of NVidia's CUDA in .net applications written in C#, Visual Basic or any other .net language.","body":"### Welcome to managedCuda\r\nmanagedCuda combines Cuda's GPU computing power with the comfort of managed .net code. While offering access to the entire feature set of Cuda's driver API, managedCuda has type safe wrapper classes for every handle defined by the API. ManagedCuda also includes wrappers for all Cuda based libraries, as there were CUFFT, CURAND, CUSPARSE, CUBLAS, CUSOLVE, NPP and NVRTC. \r\n\r\n### What managedCuda is not\r\nmanagedCuda is not a code converter, which means that no C# code will be translated to Cuda. Every cuda kernel that you want to use has to be written in CUDA-C and must be compiled to PTX or CUBIN format using the NVCC toolchain.\r\n\r\n### What managedCuda is\r\nmanagedCuda is the right library if you want to accelerate your .net application with Cuda without any restrictions. As every kernel is written in plain CUDA-C, all Cuda specific features are maintained. Even future improvements to Cuda by NVIDIA can be integrated without any changes to your application host code.\r\n\r\n### Side note\r\nCurrently managedCuda is still hosted on [codeplex](http://managedcuda.codeplex.com). Latest with the upcoming 7.5 release, managedCuda will move to github.\r\n\r\n### Sample code\r\nVectorAdd.cu as given by the Cuda SDK samples:\r\n```\r\n//Kernel code:\r\nextern \"C\"  {\t\r\n\t// Device code\r\n\t__global__ void VecAdd(const float* A, const float* B, float* C, int N)\r\n\t{\r\n\t\tint i = blockDim.x * blockIdx.x + threadIdx.x;\r\n\t\tif (i < N)\r\n\t\t\tC[i] = A[i] + B[i];\r\n\t}\r\n}\r\n```\r\n\r\nCorresponding C# code to call the kernel:\r\n```\r\nint N = 50000;\r\nint deviceID = 0;\r\nCudaContext ctx = new CudaContext(deviceID);\r\nCudaKernel kernel = ctx.LoadKernel(\"vectorAdd.ptx\", \"VecAdd\");\r\nkernel.GridDimensions = (N + 255) / 256;\r\nkernel.BlockDimensions = 256;\r\n\r\n// Allocate input vectors h_A and h_B in host memory\r\nfloat[] h_A = new float[N];\r\nfloat[] h_B = new float[N];\r\n\t\t\t\r\n// TODO: Initialize input vectors h_A, h_B\r\n\r\n// Allocate vectors in device memory and copy vectors from host memory to device memory \r\nCudaDeviceVariable<float> d_A = h_A;\r\nCudaDeviceVariable<float> d_B = h_B;\r\nCudaDeviceVariable<float> d_C = new CudaDeviceVariable<float>(N);\r\n\r\n// Invoke kernel\r\nkernel.Run(d_A.DevicePointer, d_B.DevicePointer, d_C.DevicePointer, N);\r\n\t\t\t\r\n// Copy result from device memory to host memory\r\n// h_C contains the result in host memory\r\nfloat[] h_C = d_C;\r\n```\r\n\r\nSample showing the simple and elegant integration of NPP\r\n```\r\n//Load an image\r\nBitmap bmp = new Bitmap(\"niceImage.png\");\r\n\r\n//Alloc device memory using NPP images\r\nNPPImage_8uC3 bmp_d = new NPPImage_8uC3(bmp.Width, bmp.Height);\r\nNPPImage_8uC3 bmpDest_d = new NPPImage_8uC3(bmp.Width, bmp.Height);\r\n\r\n//Copy image to GPU\r\nbmp_d.CopyToDevice(bmp);\r\n//Run a NPP function\r\nbmp_d.FilterGaussBorder(bmpDest_d, MaskSize.Size_5_X_5, NppiBorderType.Replicate);\r\n//Copy result back to host\r\nbmpDest_d.CopyToHost(bmp);\r\n//Use the result\r\nbmp.Save(\"niceImageFiltered.png\");\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}